from datetime import datetime
import os

class MamaMiaConfig:
    """MAMA-MIAæ•°æ®é›†ä¸Šçš„UltraLight VM-UNeté…ç½®"""
    
    # ==================== åŸºç¡€è®¾ç½® ====================
    network = 'UltraLight_VM_UNet_MAMA_MIA'
    datasets = 'MAMA_MIA'
    
    # ==================== æ•°æ®è·¯å¾„ ====================
    data_dir = '/root/Lty/MAMA-MIA/data/'
    seg_dir = '/root/Lty/MAMA-MIA/segmentations_expert/'
    ser_dir = '/root/Lty/MAMA-MIA/data_FTV_SER_T1/'
    pe_dir = '/root/Lty/MAMA-MIA/data_FTV_PE_T1/'
    
    # ==================== ä½¿ç”¨çš„æ•°æ®é›† ====================
    datasets_list = ['DUKE', 'NACT', 'ISPY1', 'ISPY2']
    
    # ==================== å¤šæ¨¡æ€è®¾ç½® ====================
    multimodal = False
    input_channels = 1  # å•æ¨¡æ€ä¸º1ï¼Œå¤šæ¨¡æ€ä¸º3
    
    # ==================== åŠ¨æ€æ¨¡æ€èåˆé…ç½® ====================
    enable_fusion = False  # æ˜¯å¦å¯ç”¨åŠ¨æ€æ¨¡æ€èåˆ
    fusion_verbose = False  # æ˜¯å¦è¾“å‡ºèåˆè°ƒè¯•ä¿¡æ¯
    test_weight_method = 'historical_mean'  # æµ‹è¯•æ—¶æƒé‡é€‰æ‹©æ–¹æ³•
    # å¯é€‰å€¼:
    # - 'current': ä½¿ç”¨å½“å‰æƒé‡ï¼ˆåŸå§‹å®ç°ï¼‰
    # - 'historical_mean': ä½¿ç”¨è®­ç»ƒå†å²å‡å€¼ï¼ˆæ¨èï¼‰
    # - 'historical_median': ä½¿ç”¨è®­ç»ƒå†å²ä¸­ä½æ•°
    # - 'last': ä½¿ç”¨æœ€åä¸€æ¬¡è®­ç»ƒæƒé‡
    
    # ==================== æ¨¡å‹é…ç½® ====================
    model_config = {
        'num_classes': 1,
        'input_channels': 1,  # æ ¹æ®multimodalè‡ªåŠ¨è°ƒæ•´
        'c_list': [8, 16, 24, 32, 48, 64],
        'split_att': 'fc',
        'bridge': True,
    }
    
    # ==================== è®­ç»ƒå‚æ•° ====================
    from utils import BceDiceLoss
    criterion = BceDiceLoss()
    num_classes = 1
    input_size_h = 256
    input_size_w = 256
    distributed = False
    local_rank = -1
    num_workers = 4
    seed = 42
    amp = False
    batch_size = 256
    epochs = 400
    
    # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆç”¨äºå¤§batch_sizeè®­ç»ƒï¼‰
    gradient_accumulation_steps = 1
    
    # ==================== å·¥ä½œç›®å½• ====================
    work_dir = f'results/{network}_{datetime.now().strftime("%Y%m%d_%H%M%S")}/'
    
    # ==================== æ—¥å¿—å’Œä¿å­˜é—´éš” ====================
    print_interval = 20
    val_interval = 10
    save_interval = 50
    threshold = 0.5
    
    # ==================== ä¼˜åŒ–å™¨é…ç½® ====================
    opt = 'AdamW'
    lr = 0.001
    betas = (0.9, 0.999)
    eps = 1e-8
    weight_decay = 1e-2
    amsgrad = False
    
    # ==================== å­¦ä¹ ç‡è°ƒåº¦å™¨ ====================
    sch = 'CosineAnnealingLR'
    T_max = 50
    eta_min = 1e-6
    last_epoch = -1
    
    # ==================== æ•°æ®å¢å¼ºé…ç½® ====================
    use_augmentation = False  # æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼º
    augmentation_p = 0.5  # æ•°æ®å¢å¼ºæ¦‚ç‡
    balanced_sampling = False  # æ˜¯å¦ä½¿ç”¨å¹³è¡¡é‡‡æ ·
    
    # ==================== è·¨æ•°æ®é›†æµ‹è¯•é…ç½® ====================
    cross_dataset_test = False  # æ˜¯å¦è¿›è¡Œè·¨æ•°æ®é›†æµ‹è¯•
    
    def __init__(self, **kwargs):
        """
        åˆå§‹åŒ–é…ç½®
        
        Args:
            **kwargs: è¦†ç›–é»˜è®¤é…ç½®çš„å‚æ•°
        """
        # åº”ç”¨ç”¨æˆ·æä¾›çš„å‚æ•°
        for k, v in kwargs.items():
            if hasattr(self, k):
                setattr(self, k, v)
        
                # ==================== ã€æ–°å¢ã€‘æ¨¡å‹ç±»å‹å¤„ç† ====================
        # å¦‚æœé…ç½®ä¸­æ²¡æœ‰model_typeï¼Œæ·»åŠ é»˜è®¤å€¼
        if not hasattr(self, 'model_type'):
            self.model_type = 'ultralight'
        
        # æ‰“å°æ¨¡å‹ç±»å‹ä¿¡æ¯
        print(f"ğŸ¯ Model Type: {self.model_type.upper()}")
        
        # ==================== è‡ªåŠ¨è°ƒæ•´è¾“å…¥é€šé“æ•° ====================
        if self.multimodal:
            self.input_channels = 3
            self.model_config['input_channels'] = 3
        else:
            self.input_channels = 1
            self.model_config['input_channels'] = 1
            
        # ==================== åŠ¨æ€èåˆé…ç½®éªŒè¯ ====================
        if self.enable_fusion:
            if not self.multimodal:
                print("âš ï¸ Warning: Dynamic fusion requires multimodal input. Disabling fusion.")
                self.enable_fusion = False
            else:
                print("âœ… Dynamic modal fusion ENABLED")
                print(f"   - Test weight method: {self.test_weight_method}")
                # éªŒè¯æµ‹è¯•æƒé‡æ–¹æ³•
                valid_methods = ['current', 'historical_mean', 'historical_median', 'last']
                if self.test_weight_method not in valid_methods:
                    print(f"âš ï¸ Warning: Invalid test_weight_method: {self.test_weight_method}")
                    print(f"   Valid methods are: {valid_methods}")
                    print(f"   Using default: historical_mean")
                    self.test_weight_method = 'historical_mean'
                
                if self.fusion_verbose:
                    print("   - Verbose mode: ON")
                else:
                    print("   - Verbose mode: OFF")
        else:
            if self.multimodal:
                print("â„¹ï¸  Dynamic modal fusion DISABLED (using direct 3-channel input)")
        
        # ==================== æ•°æ®é›†åˆ—è¡¨éªŒè¯ ====================
        # ç¡®ä¿datasets_listæ˜¯åˆ—è¡¨
        if isinstance(self.datasets_list, str):
            self.datasets_list = [self.datasets_list]
            
        # æ£€æŸ¥æ•°æ®é›†åç§°æœ‰æ•ˆæ€§
        valid_datasets = ['DUKE', 'NACT', 'ISPY1', 'ISPY2']
        invalid_datasets = [d for d in self.datasets_list if d not in valid_datasets]
        if invalid_datasets:
            print(f"âš ï¸ Warning: Invalid dataset names: {invalid_datasets}")
            print(f"   Valid datasets are: {valid_datasets}")
            # ç§»é™¤æ— æ•ˆæ•°æ®é›†
            self.datasets_list = [d for d in self.datasets_list if d in valid_datasets]
        
        # ==================== æ•°æ®å¢å¼ºé…ç½®éªŒè¯ ====================
        if self.use_augmentation:
            print(f"âœ… Data augmentation ENABLED (p={self.augmentation_p})")
        else:
            print("â„¹ï¸  Data augmentation DISABLED")
            
        if self.balanced_sampling:
            print("âœ… Balanced sampling ENABLED")
        else:
            print("â„¹ï¸  Balanced sampling DISABLED")
            
        # ==================== æ¢¯åº¦ç´¯ç§¯éªŒè¯ ====================
        if self.gradient_accumulation_steps > 1:
            print(f"âœ… Gradient accumulation ENABLED (steps={self.gradient_accumulation_steps})")
            # è°ƒæ•´æœ‰æ•ˆbatch size
            effective_batch_size = self.batch_size * self.gradient_accumulation_steps
            print(f"   - Effective batch size: {effective_batch_size}")
        
        # ==================== è·¨æ•°æ®é›†æµ‹è¯•é…ç½® ====================
        if self.cross_dataset_test:
            print("âœ… Cross-dataset testing ENABLED")
        
        # ==================== åˆ›å»ºå·¥ä½œç›®å½• ====================
        os.makedirs(self.work_dir, exist_ok=True)
        
        # ==================== æ‰“å°æœ€ç»ˆé…ç½®æ‘˜è¦ ====================
        self._print_config_summary()
    
    def _print_config_summary(self):
        """æ‰“å°é…ç½®æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("MAMA-MIA DATASET CONFIGURATION SUMMARY")
        print("=" * 60)
        
        # æ•°æ®é›†ä¿¡æ¯
        print(f"ğŸ“ Dataset Configuration:")
        print(f"   - Dataset: {self.datasets}")
        print(f"   - Sub-datasets: {', '.join(self.datasets_list)}")
        print(f"   - Data directory: {self.data_dir}")
        
        # æ¨¡æ€ä¿¡æ¯
        print(f"\nğŸ¯ Modal Configuration:")
        print(f"   - Multimodal: {'âœ… Yes (T1+SER+PE)' if self.multimodal else 'âŒ No (T1 only)'}")
        print(f"   - Input channels: {self.input_channels}")
        if self.multimodal:
            print(f"   - SER directory: {self.ser_dir}")
            print(f"   - PE directory: {self.pe_dir}")
        
        # åŠ¨æ€èåˆä¿¡æ¯
        if self.multimodal:
            print(f"\nğŸ”¬ Dynamic Fusion Configuration:")
            print(f"   - Enabled: {'âœ… YES' if self.enable_fusion else 'âŒ NO'}")
            if self.enable_fusion:
                print(f"   - Test weight method: {self.test_weight_method}")
                method_desc = {
                    'current': 'Use current model weights',
                    'historical_mean': 'Use mean of training history (recommended)',
                    'historical_median': 'Use median of training history',
                    'last': 'Use last training weights'
                }
                print(f"     â†³ {method_desc.get(self.test_weight_method, 'Unknown method')}")
                print(f"   - Verbose mode: {'âœ… ON' if self.fusion_verbose else 'âŒ OFF'}")
        
        # æ¨¡å‹ä¿¡æ¯
        print(f"\nğŸ¤– Model Configuration:")
        print(f"   - Network: {self.network}")
        print(f"   - Input size: {self.input_size_h}x{self.input_size_w}")
        print(f"   - Output classes: {self.num_classes}")
        print(f"   - Channel list: {self.model_config['c_list']}")
        print(f"   - Bridge: {'âœ… ENABLED' if self.model_config['bridge'] else 'âŒ DISABLED'}")
        
        # è®­ç»ƒä¿¡æ¯
        print(f"\nâš™ï¸  Training Configuration:")
        print(f"   - Batch size: {self.batch_size}")
        print(f"   - Epochs: {self.epochs}")
        print(f"   - Learning rate: {self.lr}")
        print(f"   - Optimizer: {self.opt}")
        print(f"   - Scheduler: {self.sch}")
        print(f"   - Gradient accumulation: {self.gradient_accumulation_steps}x")
        
        # æ•°æ®å¢å¼º
        print(f"   - Data augmentation: {'âœ… ENABLED' if self.use_augmentation else 'âŒ DISABLED'}")
        if self.use_augmentation:
            print(f"   - Augmentation probability: {self.augmentation_p}")
        print(f"   - Balanced sampling: {'âœ… ENABLED' if self.balanced_sampling else 'âŒ DISABLED'}")
        
        # å…¶ä»–è®¾ç½®
        print(f"\nğŸ”§ Other Settings:")
        print(f"   - Random seed: {self.seed}")
        print(f"   - Number of workers: {self.num_workers}")
        print(f"   - Mixed precision: {'âœ… ENABLED' if self.amp else 'âŒ DISABLED'}")
        print(f"   - Validation interval: every {self.val_interval} epochs")
        print(f"   - Checkpoint save interval: every {self.save_interval} epochs")
        print(f"   - Segmentation threshold: {self.threshold}")
        
        # è·¨æ•°æ®é›†æµ‹è¯•
        if self.cross_dataset_test:
            print(f"   - Cross-dataset test: âœ… ENABLED")
        
        # å·¥ä½œç›®å½•
        print(f"\nğŸ“‚ Output Directory:")
        print(f"   - {self.work_dir}")
        
        print("=" * 60 + "\n")
    
    def to_dict(self):
        """å°†é…ç½®è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äºä¿å­˜ï¼‰"""
        config_dict = {}
        for key, value in self.__dict__.items():
            if not key.startswith('_'):
                # å¤„ç†ç‰¹æ®Šç±»å‹
                if key == 'criterion' and hasattr(value, '__class__'):
                    config_dict[key] = value.__class__.__name__
                else:
                    config_dict[key] = value
        return config_dict
    
    def save(self, path=None):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        if path is None:
            path = os.path.join(self.work_dir, "config.json")
        
        import json
        with open(path, 'w') as f:
            json.dump(self.to_dict(), f, indent=2, default=str)
        print(f"ğŸ“„ Configuration saved to: {path}")
    
    @classmethod
    def load(cls, path):
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        import json
        with open(path, 'r') as f:
            config_dict = json.load(f)
        
        # å¤„ç†ç‰¹æ®Šå­—æ®µ
        if 'criterion' in config_dict and isinstance(config_dict['criterion'], str):
            if config_dict['criterion'] == 'BceDiceLoss':
                from utils import BceDiceLoss
                config_dict['criterion'] = BceDiceLoss()
        
        # åˆ›å»ºé…ç½®å®ä¾‹
        config = cls()
        
        # åº”ç”¨ä¿å­˜çš„é…ç½®
        for key, value in config_dict.items():
            if hasattr(config, key):
                setattr(config, key, value)
        
        print(f"ğŸ“‚ Configuration loaded from: {path}")
        return config
    
    def get_fusion_config_info(self):
        """è·å–èåˆé…ç½®çš„è¯¦ç»†ä¿¡æ¯"""
        if not self.multimodal or not self.enable_fusion:
            return None
        
        info = {
            'enabled': True,
            'test_weight_method': self.test_weight_method,
            'verbose': self.fusion_verbose,
            'description': {
                'current': 'ä½¿ç”¨å½“å‰æ¨¡å‹æƒé‡ï¼ˆå¯èƒ½ä¸ç¨³å®šï¼‰',
                'historical_mean': 'ä½¿ç”¨è®­ç»ƒå†å²å‡å€¼ï¼ˆæ¨èï¼Œæ›´ç¨³å¥ï¼‰',
                'historical_median': 'ä½¿ç”¨è®­ç»ƒå†å²ä¸­ä½æ•°ï¼ˆæŠ—å¼‚å¸¸å€¼ï¼‰',
                'last': 'ä½¿ç”¨æœ€åä¸€æ¬¡è®­ç»ƒæƒé‡'
            }
        }
        
        return info


# ==================== é…ç½®éªŒè¯å‡½æ•° ====================
def validate_config(config):
    """
    éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§
    
    Args:
        config: MamaMiaConfigå®ä¾‹
        
    Returns:
        bool: é…ç½®æ˜¯å¦æœ‰æ•ˆ
        str: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæ— æ•ˆï¼‰
    """
    errors = []
    
    # æ£€æŸ¥å¿…è¦ç›®å½•æ˜¯å¦å­˜åœ¨
    required_dirs = [
        (config.data_dir, "Data directory"),
        (config.seg_dir, "Segmentation directory"),
    ]
    
    if config.multimodal:
        required_dirs.extend([
            (config.ser_dir, "SER directory"),
            (config.pe_dir, "PE directory"),
        ])
    
    for dir_path, dir_name in required_dirs:
        if not os.path.exists(dir_path):
            errors.append(f"{dir_name} does not exist: {dir_path}")
    
    # æ£€æŸ¥æ•°æ®é›†åˆ—è¡¨
    if not config.datasets_list:
        errors.append("No datasets specified in datasets_list")
    
    # æ£€æŸ¥æ¨¡å‹é…ç½®
    if config.model_config['input_channels'] not in [1, 3]:
        errors.append(f"Invalid input_channels: {config.model_config['input_channels']}. Must be 1 or 3.")
    
    # æ£€æŸ¥åŠ¨æ€èåˆé…ç½®
    if config.enable_fusion and not config.multimodal:
        errors.append("Dynamic fusion requires multimodal input (multimodal=True)")
    
    # æ£€æŸ¥æµ‹è¯•æƒé‡æ–¹æ³•
    valid_weight_methods = ['current', 'historical_mean', 'historical_median', 'last']
    if config.test_weight_method not in valid_weight_methods:
        errors.append(f"Invalid test_weight_method: {config.test_weight_method}. Must be one of {valid_weight_methods}")
    
    # æ£€æŸ¥å­¦ä¹ ç‡
    if config.lr <= 0:
        errors.append(f"Invalid learning rate: {config.lr}. Must be > 0.")
    
    # æ£€æŸ¥batch size
    if config.batch_size <= 0:
        errors.append(f"Invalid batch size: {config.batch_size}. Must be > 0.")
    
    # æ£€æŸ¥æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
    if config.gradient_accumulation_steps <= 0:
        errors.append(f"Invalid gradient accumulation steps: {config.gradient_accumulation_steps}. Must be > 0.")
    
    if errors:
        print("âŒ Configuration validation failed:")
        for error in errors:
            print(f"   - {error}")
        return False, "\n".join(errors)
    
    print("âœ… Configuration validation passed")
    return True, None


# ==================== é…ç½®åˆ›å»ºè¾…åŠ©å‡½æ•° ====================
def create_fusion_config(name="fusion_experiment", multimodal=True, enable_fusion=True, 
                        test_weight_method='historical_mean', **kwargs):
    """
    åˆ›å»ºå¯ç”¨åŠ¨æ€èåˆçš„é…ç½®
    
    Args:
        name: å®éªŒåç§°
        multimodal: æ˜¯å¦ä½¿ç”¨å¤šæ¨¡æ€
        enable_fusion: æ˜¯å¦å¯ç”¨åŠ¨æ€èåˆ
        test_weight_method: æµ‹è¯•æ—¶æƒé‡é€‰æ‹©æ–¹æ³•
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
        
    Returns:
        MamaMiaConfigå®ä¾‹
    """
    base_kwargs = {
        'network': f'Enhanced_{name}',
        'multimodal': multimodal,
        'enable_fusion': enable_fusion,
        'test_weight_method': test_weight_method,
        'fusion_verbose': kwargs.get('fusion_verbose', False),
        'datasets_list': kwargs.get('datasets_list', ['DUKE', 'NACT', 'ISPY1', 'ISPY2']),
    }
    
    # åˆå¹¶ç”¨æˆ·æä¾›çš„å‚æ•°
    base_kwargs.update(kwargs)
    
    return MamaMiaConfig(**base_kwargs)


def create_baseline_config(name="baseline_experiment", multimodal=True, **kwargs):
    """
    åˆ›å»ºåŸºçº¿é…ç½®ï¼ˆç¦ç”¨åŠ¨æ€èåˆï¼‰
    
    Args:
        name: å®éªŒåç§°
        multimodal: æ˜¯å¦ä½¿ç”¨å¤šæ¨¡æ€
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
        
    Returns:
        MamaMiaConfigå®ä¾‹
    """
    base_kwargs = {
        'network': f'Baseline_{name}',
        'multimodal': multimodal,
        'enable_fusion': False,
        'fusion_verbose': False,
        'datasets_list': kwargs.get('datasets_list', ['DUKE', 'NACT', 'ISPY1', 'ISPY2']),
    }
    
    # åˆå¹¶ç”¨æˆ·æä¾›çš„å‚æ•°
    base_kwargs.update(kwargs)
    
    return MamaMiaConfig(**base_kwargs)


def create_comparison_configs(name_prefix="experiment", multimodal=True, 
                             test_methods=['current', 'historical_mean', 'historical_median', 'last'], **kwargs):
    """
    åˆ›å»ºå¤šä¸ªé…ç½®ç”¨äºæ¯”è¾ƒä¸åŒçš„æµ‹è¯•æƒé‡æ–¹æ³•
    
    Args:
        name_prefix: å®éªŒåç§°å‰ç¼€
        multimodal: æ˜¯å¦ä½¿ç”¨å¤šæ¨¡æ€
        test_methods: è¦æµ‹è¯•çš„æ–¹æ³•åˆ—è¡¨
        **kwargs: å…¶ä»–é…ç½®å‚æ•°
        
    Returns:
        dict: æ–¹æ³•ååˆ°é…ç½®çš„æ˜ å°„
    """
    configs = {}
    
    for method in test_methods:
        config_name = f"{name_prefix}_{method}"
        configs[method] = create_fusion_config(
            name=config_name,
            multimodal=multimodal,
            enable_fusion=True,
            test_weight_method=method,
            **kwargs
        )
    
    return configs


# ==================== ç¤ºä¾‹ç”¨æ³• ====================
if __name__ == "__main__":
    print("Testing MamaMiaConfig class...\n")
    
    # ç¤ºä¾‹1ï¼šåˆ›å»ºä½¿ç”¨å†å²å‡å€¼çš„èåˆé…ç½®
    print("Example 1: Configuration with historical mean fusion")
    config_fusion = create_fusion_config(
        name="test_historical_mean",
        multimodal=True,
        enable_fusion=True,
        test_weight_method='historical_mean',
        fusion_verbose=True,
        batch_size=256,
        epochs=50
    )
    
    # éªŒè¯é…ç½®
    is_valid, error_msg = validate_config(config_fusion)
    
    if is_valid:
        print("\nâœ… Fusion configuration is valid")
        
        # æ˜¾ç¤ºèåˆé…ç½®ä¿¡æ¯
        fusion_info = config_fusion.get_fusion_config_info()
        if fusion_info:
            print(f"\nğŸ”¬ Fusion Configuration Details:")
            print(f"   - Method: {fusion_info['test_weight_method']}")
            print(f"   - Description: {fusion_info['description'][fusion_info['test_weight_method']]}")
        
        config_fusion.save()
    else:
        print(f"\nâŒ Fusion configuration is invalid: {error_msg}")
    
    print("\n" + "-" * 60 + "\n")
    
    # ç¤ºä¾‹2ï¼šåˆ›å»ºæ¯”è¾ƒä¸åŒæ–¹æ³•çš„é…ç½®
    print("Example 2: Creating comparison configurations for different test methods")
    comparison_configs = create_comparison_configs(
        name_prefix="comparison",
        multimodal=True,
        test_methods=['current', 'historical_mean', 'historical_median'],
        batch_size=16,
        epochs=100
    )
    
    for method, config in comparison_configs.items():
        print(f"\nğŸ“‹ {method.upper()} configuration:")
        print(f"   - Network: {config.network}")
        print(f"   - Test method: {config.test_weight_method}")
    
    print("\n" + "-" * 60 + "\n")
    
    # ç¤ºä¾‹3ï¼šåˆ›å»ºåŸºçº¿é…ç½®
    print("Example 3: Baseline configuration (no fusion)")
    config_baseline = create_baseline_config(
        name="test_baseline",
        multimodal=True,
        batch_size=256,
        epochs=200
    )
    
    # éªŒè¯é…ç½®
    is_valid, error_msg = validate_config(config_baseline)
    
    if is_valid:
        print("\nâœ… Baseline configuration is valid")
        config_baseline.save()
    else:
        print(f"\nâŒ Baseline configuration is invalid: {error_msg}")
    
    print("\nâœ¨ Configuration test completed successfully!")