import torch
from torch import nn
from torch.cuda.amp import autocast, GradScaler
import os
import sys
import argparse
import gc
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

from utils import *
from config_setting_mama_mia import MamaMiaConfig
from mama_mia_loader import MAMAMIADataLoader
from engine import train_one_epoch, val_one_epoch

# ==================== ã€æ–°å¢å¯¼å…¥ã€‘ ====================
# å¯¼å…¥å¢å¼ºç‰ˆæ¨¡å‹
try:
    from models.ultralight_vm_unet_enhanced import create_ultralight_model
    USE_ENHANCED_MODEL = True
    print("âœ… Enhanced model module found")
except ImportError:
    # å¦‚æœå¢å¼ºç‰ˆæ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹ï¼ˆå‘åå…¼å®¹ï¼‰
    from models.UltraLight_VM_UNet import UltraLight_VM_UNet
    USE_ENHANCED_MODEL = False
    print("âš ï¸ Enhanced model module not found, using original model")
# ==================== ã€æ–°å¢ç»“æŸã€‘ ====================

import warnings
warnings.filterwarnings("ignore")

def print_memory_usage():
    """æ‰“å°å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated() / 1024**3
        print(f"GPU Memory: {gpu_memory:.2f}GB")

def parse_args():
    parser = argparse.ArgumentParser(description='UltraLight VM-UNet Training for MAMA-MIA')
    parser.add_argument('--name', type=str, required=True, help='Experiment name')
    parser.add_argument('--multimodal', action='store_true', help='Use multimodal input (T1+SER+PE)')
    parser.add_argument('--datasets', nargs='+', required=True, 
                       help='Datasets to use for training, e.g., DUKE NACT ISPY1 ISPY2')
    parser.add_argument('--batch_size', type=int, default=8, help='Batch size for training')
    parser.add_argument('--epochs', type=int, default=400, help='Number of training epochs')
    parser.add_argument('--lr', type=float, default=0.001, help='Learning rate')
    parser.add_argument('--resume', type=str, default='', help='Resume from checkpoint')
    parser.add_argument('--input_channels', type=int, default=1, help='Input channels')
    parser.add_argument('--data_dir', type=str, default='/root/autodl-tmp/Lty/MAMA_MIA/data/', help='Data directory')
    parser.add_argument('--seg_dir', type=str, default='/root/autodl-tmp/Lty/MAMA_MIA/segmentations_expert/', help='Segmentation directory')
    parser.add_argument('--ser_dir', type=str, default='/root/autodl-tmp/Lty/MAMA_MIA/data_FTV_SER_T1/', help='SER directory')
    parser.add_argument('--pe_dir', type=str, default='/root/autodl-tmp/Lty/MAMA_MIA/data_FTV_PE_T1/', help='PE directory')
    parser.add_argument('--num_workers', type=int, default=2, help='Number of data loading workers')
    parser.add_argument('--skip_flops', action='store_true', help='Skip FLOPs calculation')
    
    # ã€åŸæœ‰å‚æ•°ã€‘
    parser.add_argument('--balanced_sampling', action='store_true', help='Use balanced sampling for class imbalance')
    parser.add_argument('--data_augmentation', action='store_true', help='Use data augmentation during training')
    parser.add_argument('--augmentation_p', type=float, default=0.5, help='Probability for data augmentation')
    
    # ==================== ã€æ–°å¢å‚æ•°ã€‘ ====================
    # åŠ¨æ€èåˆå‚æ•°
    parser.add_argument('--enable_fusion', action='store_true', 
                       help='Enable dynamic modal fusion (requires multimodal)')
    parser.add_argument('--fusion_verbose', action='store_true',
                       help='Enable verbose output for fusion module')
    parser.add_argument('--test_weight_method', type=str, default='historical_mean',
                       choices=['current', 'historical_mean', 'historical_median', 'last'],
                       help='Test weight selection method for dynamic fusion')
    # ==================== ã€æ–°å¢ç»“æŸã€‘ ====================
    
    return parser.parse_args()

def main():
    args = parse_args()
    
    def clean_state_dict(state_dict):
        """æ¸…ç†state_dictï¼Œç§»é™¤thopæ·»åŠ çš„é¢å¤–å‚æ•°"""
        cleaned_state_dict = {}
        removed_keys = []
        for key, value in state_dict.items():
            if 'total_ops' not in key and 'total_params' not in key:
                cleaned_state_dict[key] = value
            else:
                removed_keys.append(key)
        
        if removed_keys:
            print(f"Cleaned {len(removed_keys)} extra parameters from state_dict")
        return cleaned_state_dict
    
    print("=== Configuration Summary ===")
    print(f"Experiment Name: {args.name}")
    print(f"Multimodal: {args.multimodal}")
    if args.multimodal:
        print("âœ“ Using T1 + SER + PE multimodal input")
    else:
        print("âœ“ Using T1 only single modal input")
    
    # ==================== ã€æ–°å¢ã€‘æ˜¾ç¤ºèåˆé…ç½® ====================
    if args.multimodal:
        if args.enable_fusion:
            print("ğŸ¯ Dynamic Modal Fusion: âœ… ENABLED")
            if args.fusion_verbose:
                print("   - Verbose mode: âœ… ON")
        else:
            print("ğŸ¯ Dynamic Modal Fusion: âŒ DISABLED (direct 3-channel input)")
    # ==================== ã€æ–°å¢ç»“æŸã€‘ ====================
    
    print(f"Datasets: {args.datasets}")
    print(f"Batch Size: {args.batch_size}")
    print(f"Epochs: {args.epochs}")
    print(f"Learning Rate: {args.lr}")
    print(f"Input Channels: {args.input_channels}")
    print(f"Data Workers: {args.num_workers}")
    print(f"Data Directory: {args.data_dir}")
    # ã€åŸæœ‰ã€‘æ˜¾ç¤ºå¹³è¡¡é‡‡æ ·å’Œæ•°æ®å¢å¹¿é…ç½®
    print(f"Balanced Sampling: {args.balanced_sampling}")
    print(f"Data Augmentation: {args.data_augmentation}")
    if args.data_augmentation:
        print(f"Augmentation Probability: {args.augmentation_p}")
    print("=============================")
    
    # åˆ›å»ºé…ç½®
    config = MamaMiaConfig(
        multimodal=args.multimodal,
        datasets_list=args.datasets,
        batch_size=args.batch_size,
        epochs=args.epochs,
        lr=args.lr,
        input_channels=args.input_channels,
        data_dir=args.data_dir,
        seg_dir=args.seg_dir,
        ser_dir=args.ser_dir,
        pe_dir=args.pe_dir,
        num_workers=args.num_workers,
        # ==================== ã€æ–°å¢ã€‘ä¼ é€’èåˆå‚æ•° ====================
        enable_fusion=args.enable_fusion,
        fusion_verbose=args.fusion_verbose,
        test_weight_method=args.test_weight_method,
        # ==================== ã€æ–°å¢ç»“æŸã€‘ ====================
        balanced_sampling=args.balanced_sampling,
        use_augmentation=args.data_augmentation,
        augmentation_p=args.augmentation_p
    )
    
    # ã€åŸæœ‰ã€‘è®¾ç½®å¹³è¡¡é‡‡æ ·å’Œæ•°æ®å¢å¹¿å‚æ•°
    config.balanced_sampling = args.balanced_sampling
    config.use_augmentation = args.data_augmentation
    config.augmentation_p = args.augmentation_p
    
    # ã€åŸæœ‰ã€‘è®¾ç½®å®Œæ•´çš„éšæœºç§å­
    print('#----------Setting random seed for reproducibility----------#')
    set_seed(config.seed)
    
    # è®¾ç½®å·¥ä½œç›®å½•
    config.work_dir = f'results/{args.name}'
    config.network = args.name

    print('#----------Creating logger----------#')
    log_dir = os.path.join(config.work_dir, 'log')
    checkpoint_dir = os.path.join(config.work_dir, 'checkpoints')
    resume_model = os.path.join(checkpoint_dir, 'latest.pth')
    outputs = os.path.join(config.work_dir, 'outputs')
    
    if not os.path.exists(checkpoint_dir):
        os.makedirs(checkpoint_dir)
    if not os.path.exists(outputs):
        os.makedirs(outputs)

    global logger
    logger = get_logger('train', log_dir)
    log_config_info(config, logger)

    print('#----------GPU init----------#')
    gpu_ids = [0]
    torch.cuda.empty_cache()

    print('#----------Preparing dataset----------#')
    data_loader = MAMAMIADataLoader(config)
    
    try:
        train_loader = data_loader.get_train_loader()
        val_loader = data_loader.get_val_loader()
        test_loader = data_loader.get_test_loader()
        
        # ã€åŸæœ‰ã€‘ä¸ºDataLoaderè®¾ç½®éšæœºç§å­
        train_loader = seed_data_loader(train_loader, config.seed)
        val_loader = seed_data_loader(val_loader, config.seed)
        test_loader = seed_data_loader(test_loader, config.seed)
        
    except Exception as e:
        print(f"Error loading datasets: {e}")
        print("Please check:")
        print("1. Dataset names are correct: DUKE, NACT, ISPY1, ISPY2")
        print("2. Data directories exist and contain the required files")
        print("3. For multimodal, ensure SER and PE directories contain the required files")
        return

    print(f'Train samples: {len(train_loader.dataset)}')
    print(f'Val samples: {len(val_loader.dataset)}')
    print(f'Test samples: {len(test_loader.dataset)}')
    
    if len(train_loader.dataset) == 0:
        print("ERROR: No training samples found! Please check your dataset configuration.")
        return

    print('#----------Preparing Models----------#')
    
    # ==================== ã€æ–°å¢ã€‘æ¨¡å‹åˆ›å»ºé€»è¾‘ ====================
    if USE_ENHANCED_MODEL:
        # ä½¿ç”¨å¢å¼ºç‰ˆæ¨¡å‹ï¼ˆæ”¯æŒåŠ¨æ€èåˆï¼‰
        model = create_ultralight_model(
            config,
            enable_fusion=config.enable_fusion,
            fusion_verbose=config.fusion_verbose,
            test_weight_method=config.test_weight_method 
        )
        model_type = "Enhanced UltraLight VM-UNet"
    else:
        # ä½¿ç”¨åŸå§‹æ¨¡å‹ï¼ˆå‘åå…¼å®¹ï¼‰
        model = UltraLight_VM_UNet(
            num_classes=config.model_config['num_classes'],
            input_channels=config.model_config['input_channels'],
            c_list=config.model_config['c_list'],
            split_att=config.model_config['split_att'],
            bridge=config.model_config['bridge'],
        )
        model_type = "Original UltraLight VM-UNet"
        if config.enable_fusion:
            print("âš ï¸ Warning: Fusion requested but enhanced model not available")
            print("   Using original model without fusion")
    # ==================== ã€æ–°å¢ç»“æŸã€‘ ====================
    
    # ã€åŸæœ‰ã€‘ç¡®ä¿æ¨¡å‹æƒé‡åˆå§‹åŒ–ä¹Ÿæ˜¯ç¡®å®šçš„
    def init_weights(m):
        if isinstance(m, nn.Conv2d):
            torch.nn.init.kaiming_normal_(m.weight)
            if m.bias is not None:
                torch.nn.init.constant_(m.bias, 0)
        elif isinstance(m, nn.BatchNorm2d):
            torch.nn.init.constant_(m.weight, 1)
            torch.nn.init.constant_(m.bias, 0)
    
    model.apply(init_weights)
    
    print("\n=== Model Information ===")
    print(f"Model Type: {model_type}")
    if USE_ENHANCED_MODEL and hasattr(model, 'fusion_enabled'):
        print(f"Dynamic Fusion: {'âœ… Enabled' if model.fusion_enabled else 'âŒ Disabled'}")
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"Total parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")
    print(f"Model size: {total_params * 4 / 1024**2:.2f} MB")
    
    # ã€åŸæœ‰ã€‘è®¡ç®—FLOPsï¼ˆå¯é€‰ï¼Œè·³è¿‡å¯èƒ½å¯¼è‡´é”™è¯¯ï¼‰
    if not args.skip_flops:
        try:
            from thop import profile
            # å…ˆå°†æ¨¡å‹ç§»åˆ°GPUï¼Œç„¶åè®¡ç®—FLOPs
            model_temp = model.cuda()
            dummy_input = torch.randn(1, config.input_channels, 256, 256).cuda()
            flops, params = profile(model_temp, inputs=(dummy_input,), verbose=False)
            print(f"FLOPs: {flops / 1e9:.2f} G")
            print(f"Params: {params / 1e6:.2f} M")
            logger.info(f'Model FLOPs: {flops/1e9:.2f}G, Params: {params/1e6:.2f}M')
            # æ¸…ç†ä¸´æ—¶æ¨¡å‹
            del model_temp, dummy_input
            torch.cuda.empty_cache()
        except ImportError:
            print("thop not installed, skipping FLOPs calculation")
        except Exception as e:
            print(f"FLOPs calculation failed: {e}")
            print("Skipping FLOPs calculation...")
    else:
        print("Skipping FLOPs calculation as requested")
    
    # æ­£å¼å°†æ¨¡å‹ç§»åˆ°GPU
    model = torch.nn.DataParallel(model.cuda(), device_ids=gpu_ids, output_device=gpu_ids[0])

    print('#----------Prepareing loss, opt, sch and amp----------#')
    criterion = config.criterion
    optimizer = get_optimizer(config, model)
    scheduler = get_scheduler(config, optimizer)
    scaler = GradScaler() if config.amp else None

    print('#----------Set other params----------#')
    min_loss = 999
    start_epoch = 1
    min_epoch = 1
    best_val_loss = float('inf')
    
    # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
    import time
    start_time = time.time()

    # æ¢å¤è®­ç»ƒ
    if args.resume and os.path.exists(args.resume):
        print(f'#----------Resume Model from {args.resume}----------#')
        checkpoint = torch.load(args.resume, map_location=torch.device('cuda'))
        model.module.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        saved_epoch = checkpoint['epoch']
        start_epoch += saved_epoch
        min_loss, min_epoch, loss = checkpoint['min_loss'], checkpoint['min_epoch'], checkpoint['loss']
        best_val_loss = min_loss

        log_info = f'resuming model from {args.resume}. resume_epoch: {saved_epoch}, min_loss: {min_loss:.4f}, min_epoch: {min_epoch}, loss: {loss:.4f}'
        logger.info(log_info)

    print('\n#----------Training Started----------#')
    print(f"Total epochs: {config.epochs}")
    print(f"Training samples per epoch: {len(train_loader)}")
    print(f"Validation interval: every {config.val_interval} epochs")
    print(f"Checkpoint saving: every {config.save_interval} epochs")
    
    # ã€åŸæœ‰ã€‘æ˜¾ç¤ºå¹³è¡¡é‡‡æ ·å’Œæ•°æ®å¢å¹¿çŠ¶æ€
    if config.balanced_sampling:
        print("âœ“ Balanced Sampling: ENABLED")
    else:
        print("âœ— Balanced Sampling: DISABLED")
    if config.use_augmentation:
        print(f"âœ“ Data Augmentation: ENABLED (p={config.augmentation_p})")
    else:
        print("âœ— Data Augmentation: DISABLED")
    
    # ==================== ã€æ–°å¢ã€‘æ˜¾ç¤ºèåˆçŠ¶æ€ ====================
    if USE_ENHANCED_MODEL and hasattr(model.module, 'fusion_enabled'):
        if model.module.fusion_enabled:
            print("ğŸ¯ Dynamic Fusion: âœ… ENABLED")
            print(f"   - Test weight method: {model.module.test_weight_method}")
            print(f"   - Verbose mode: {'âœ… ON' if config.fusion_verbose else 'âŒ OFF'}")
        else:
            print("ğŸ¯ Dynamic Fusion: âŒ DISABLED")
    # ==================== ã€æ–°å¢ç»“æŸã€‘ ====================
    
    print_memory_usage()
    
    # ==================== ã€æ–°å¢ã€‘èåˆåˆ†æä¿å­˜ç›®å½• ====================
    if config.enable_fusion and USE_ENHANCED_MODEL:
        fusion_analysis_dir = os.path.join(config.work_dir, "fusion_analysis")
        os.makedirs(fusion_analysis_dir, exist_ok=True)
        print(f"ğŸ“Š Fusion analysis will be saved to: {fusion_analysis_dir}")
    # ==================== ã€æ–°å¢ç»“æŸã€‘ ====================

    for epoch in range(start_epoch, config.epochs + 1):
        epoch_start_time = time.time()
        
        # æ¸…ç†å†…å­˜
        torch.cuda.empty_cache()
        gc.collect()

        print(f'\n=== Epoch {epoch}/{config.epochs} ===')
        print(f'Learning Rate: {optimizer.param_groups[0]["lr"]:.6f}')
        
        # ã€åŸæœ‰ã€‘æ˜¾ç¤ºepochå¼€å§‹å‰çš„æ˜¾å­˜çŠ¶æ€
        if torch.cuda.is_available():
            memory_before = torch.cuda.memory_allocated() / 1024**3
            print(f'GPU Memory before training: {memory_before:.2f}GB')
        
        # è®­ç»ƒä¸€ä¸ªepoch
        train_loss = train_one_epoch(
            train_loader,
            model,
            criterion,
            optimizer,
            scheduler,
            epoch,
            logger,
            config,
            scaler=scaler
        )

        # ã€åŸæœ‰ã€‘è®­ç»ƒåæ˜¾ç¤ºæ˜¾å­˜å˜åŒ–
        if torch.cuda.is_available():
            memory_after = torch.cuda.memory_allocated() / 1024**3
            print(f'GPU Memory after training: {memory_after:.2f}GB')
        
        # æ¯ä¸ªepochéƒ½è¿›è¡ŒéªŒè¯
        print(f'\n--- Validation Epoch {epoch} ---')
        val_loss = val_one_epoch(
            val_loader,
            model,
            criterion,
            epoch,
            logger,
            config
        )
        
        # ==================== ã€æ–°å¢ã€‘èåˆåˆ†æï¼ˆæ¯10ä¸ªepochï¼‰ ====================
        if config.enable_fusion and USE_ENHANCED_MODEL and epoch % 10 == 0:
            try:
                if hasattr(model.module, 'analyze_fusion'):
                    analysis = model.module.analyze_fusion()
                    if analysis and analysis.get("status") == "success":
                        print(f"\nğŸ” Fusion Analysis Epoch {epoch}:")
                        weights = analysis["modal_weights"]
                        print(f"  T1 weight: {weights['T1_mean']:.3f} Â± {weights['T1_std']:.3f}")
                        print(f"  SER weight: {weights['SER_mean']:.3f} Â± {weights['SER_std']:.3f}")
                        print(f"  PE weight: {weights['PE_mean']:.3f} Â± {weights['PE_std']:.3f}")
                        
                        # ä¿å­˜é˜¶æ®µæ€§åˆ†æ
                        if epoch % 50 == 0:
                            epoch_fusion_dir = os.path.join(fusion_analysis_dir, f"epoch_{epoch}")
                            model.module.visualize_fusion(epoch_fusion_dir)
            except Exception as e:
                print(f"âš ï¸ Fusion analysis failed: {e}")
        # ==================== ã€æ–°å¢ç»“æŸã€‘ ====================
        
        # ã€åŸæœ‰ã€‘epochç»“æŸåå¼ºåˆ¶æ¸…ç†
        torch.cuda.synchronize()  # ç¡®ä¿æ‰€æœ‰CUDAæ“ä½œå®Œæˆ
        torch.cuda.empty_cache()
        gc.collect()

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            min_epoch = epoch
            # ä½¿ç”¨æ¸…ç†åçš„state_dictä¿å­˜æ¨¡å‹
            torch.save(clean_state_dict(model.module.state_dict()), os.path.join(checkpoint_dir, 'best.pth'))
            print(f'>>> ğŸ¯ New best model saved! Epoch: {epoch}, Val Loss: {val_loss:.4f}')

        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if epoch % config.save_interval == 0 or epoch == config.epochs:
            torch.save(
                {
                    'epoch': epoch,
                    'min_loss': best_val_loss,
                    'min_epoch': min_epoch,
                    'loss': val_loss,
                    'model_state_dict': clean_state_dict(model.module.state_dict()),  # ä½¿ç”¨æ¸…ç†åçš„state_dict
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                }, os.path.join(checkpoint_dir, 'latest.pth'))
            print(f'>>> ğŸ’¾ Checkpoint saved at epoch {epoch}')

        # è®¡ç®—epochæ—¶é—´
        epoch_time = time.time() - epoch_start_time
        print(f'Epoch {epoch} completed in {epoch_time:.2f}s')
        print_memory_usage()

    # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
    total_time = time.time() - start_time
    print(f'\n=== Training Completed ===')
    print(f'Total training time: {total_time:.2f}s ({total_time/60:.2f}min)')
    print(f'Best validation loss: {best_val_loss:.4f} at epoch {min_epoch}')

    # é‡å‘½åæœ€ä½³æ¨¡å‹æ–‡ä»¶ï¼ˆä¸åŸå§‹é€»è¾‘ä¸€è‡´ï¼‰
    best_model_path = os.path.join(checkpoint_dir, 'best.pth')
    if os.path.exists(best_model_path):
        new_best_model_path = os.path.join(checkpoint_dir, f'best-epoch{min_epoch}-loss{best_val_loss:.4f}.pth')
        os.rename(best_model_path, new_best_model_path)
        print(f'>>> ğŸ“ Best model renamed to: {new_best_model_path}')

    # ==================== ã€æ–°å¢ã€‘è®­ç»ƒåç”Ÿæˆå®Œæ•´èåˆåˆ†ææŠ¥å‘Š ====================
    if config.enable_fusion and USE_ENHANCED_MODEL:
        print("\nğŸ“Š Generating final fusion analysis report...")
        try:
            final_fusion_dir = os.path.join(config.work_dir, "final_fusion_analysis")
            model.module.visualize_fusion(final_fusion_dir)
            print(f"âœ… Final fusion analysis saved to: {final_fusion_dir}")
        except Exception as e:
            print(f"âš ï¸ Final fusion analysis failed: {e}")
    # ==================== ã€æ–°å¢ç»“æŸã€‘ ====================

    print("\nğŸ‰ Training completed successfully!")
    print(f"Best model saved as: {new_best_model_path}")
    
    # ã€åŸæœ‰ã€‘åœ¨æç¤ºä¿¡æ¯ä¸­åŒ…å«æ–°å‚æ•°
    multimodal_flag = "--multimodal" if args.multimodal else ""
    balanced_flag = "--balanced_sampling" if args.balanced_sampling else ""
    aug_flag = "--data_augmentation" if args.data_augmentation else ""
    
    # ==================== ã€æ–°å¢ã€‘åœ¨æç¤ºä¸­åŒ…å«èåˆå‚æ•° ====================
    fusion_flag = "--enable_fusion" if args.enable_fusion else ""
    fusion_verbose_flag = "--fusion_verbose" if args.fusion_verbose else ""
    test_method_flag = f"--test_weight_method {args.test_weight_method}" if args.enable_fusion else ""
    # ==================== ã€æ–°å¢ç»“æŸã€‘ ====================
    
    print(f"\nğŸ“‹ Testing command:")
    print(f"python test_mama_mia_ultralight_advanced.py \\")
    print(f"  --name {args.name} \\")
    print(f"  --datasets {' '.join(args.datasets)} \\")
    print(f"  {multimodal_flag} \\")
    print(f"  {balanced_flag} \\")
    print(f"  {aug_flag} \\")
    # ==================== ã€æ–°å¢ã€‘æ·»åŠ èåˆå‚æ•°åˆ°æµ‹è¯•å‘½ä»¤ ====================
    if args.enable_fusion:
        print(f"  {fusion_flag} \\")
        print(f"  {test_method_flag} \\")
        if args.fusion_verbose:
            print(f"  {fusion_verbose_flag} \\")
        print(f"  --analyze_fusion  # å¯é€‰ï¼šç”Ÿæˆèåˆåˆ†ææŠ¥å‘Š")
    # ==================== ã€æ–°å¢ç»“æŸã€‘ ====================

if __name__ == '__main__':
    main()