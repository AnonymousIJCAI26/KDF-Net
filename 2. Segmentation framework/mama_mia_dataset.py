import os
import numpy as np
import torch
from torch.utils.data import Dataset
import nibabel as nib
from glob import glob
import re
from typing import List, Dict, Optional, Union
from scipy.ndimage import zoom
import random
from torchvision.transforms import functional as F 

class MAMAMIAMultiModalAugmentation:
    """ä¸“é—¨ä¸ºå¤šæ¨¡æ€MRIè®¾è®¡çš„æ•°æ®å¢å¹¿"""
    
    def __init__(self, p=0.5):
        self.p = p
        
    def __call__(self, image, mask):
        """
        image: [3, H, W] - ä¸‰é€šé“ [T1, SER, PE]
        mask: [1, H, W] - åˆ†å‰²æ ‡ç­¾
        """
        # éšæœºæ—‹è½¬å’Œç¿»è½¬
        if random.random() < self.p:
            image, mask = self.random_rot_flip(image, mask)
        # éšæœºå°è§’åº¦æ—‹è½¬
        if random.random() < self.p:
            image, mask = self.random_rotate(image, mask)
        # éšæœºå¼ºåº¦æ‰°åŠ¨
        if random.random() < self.p:
            image, mask = self.random_intensity_shift(image, mask)
            
        return image, mask
    
    def random_rot_flip(self, image, mask):
        """æ—‹è½¬å’Œç¿»è½¬ - æ‰€æœ‰æ¨¡æ€åŒæ­¥"""
        # éšæœºæ—‹è½¬ (0, 90, 180, 270åº¦)
        k = random.randint(0, 3)
        image = torch.rot90(image, k, [1, 2])  # æ‰€æœ‰é€šé“ä¸€èµ·æ—‹è½¬
        mask = torch.rot90(mask, k, [1, 2])
        
        # éšæœºç¿»è½¬
        if random.random() > 0.5:
            image = torch.flip(image, [1])  # æ°´å¹³ç¿»è½¬
            mask = torch.flip(mask, [1])
        if random.random() > 0.5:
            image = torch.flip(image, [2])  # å‚ç›´ç¿»è½¬
            mask = torch.flip(mask, [2])
            
        return image, mask
    
    def random_rotate(self, image, mask, angle_range=(-15, 15)):
        """å°è§’åº¦æ—‹è½¬ - é¿å…ä¿¡æ¯ä¸¢å¤±"""
        angle = random.uniform(angle_range[0], angle_range[1])
        
        # å¯¹æ¯ä¸ªé€šé“åˆ†åˆ«æ—‹è½¬ï¼ˆä½†ä½¿ç”¨ç›¸åŒçš„è§’åº¦ï¼‰
        rotated_channels = []
        for i in range(image.shape[0]):
            channel_img = image[i].unsqueeze(0)  # [1, H, W]
            rotated_channel = F.rotate(channel_img, angle, interpolation=F.InterpolationMode.BILINEAR)
            rotated_channels.append(rotated_channel)
        
        image = torch.cat(rotated_channels, dim=0)
        mask = F.rotate(mask, angle, interpolation=F.InterpolationMode.NEAREST)
        
        return image, mask
    
    def random_intensity_shift(self, image, mask):
        """å¯¹æ¯ä¸ªæ¨¡æ€åˆ†åˆ«è¿›è¡Œå¼ºåº¦æ‰°åŠ¨"""
        for i in range(image.shape[0]):  # å¯¹æ¯ä¸ªæ¨¡æ€é€šé“
            if random.random() < 0.3:  # 30%æ¦‚ç‡æ‰°åŠ¨è¯¥æ¨¡æ€
                # å°å¹…åº¦çš„äº®åº¦å’Œå¯¹æ¯”åº¦å˜åŒ–
                alpha = random.uniform(0.9, 1.1)  # å¯¹æ¯”åº¦
                beta = random.uniform(-0.1, 0.1)  # äº®åº¦
                image[i] = alpha * image[i] + beta
                # ç¡®ä¿æ•°å€¼èŒƒå›´åˆç†
                image[i] = torch.clamp(image[i], -3, 3)
                
        return image, mask


# é€šç”¨çš„3Dæ•°æ®åŠ è½½å’Œé¢„å¤„ç†
class MAMAMIADataset(Dataset):
    """
    MAMA-MIA 3D MRIåˆ†å‰²æ•°æ®é›†åŠ è½½å™¨
    æ”¯æŒDUKEã€NACTã€ISPY1ã€ISPY2å››ä¸ªå­æ•°æ®é›†
    ã€æ–°å¢ã€‘æ”¯æŒè·¨æ•°æ®é›†å®Œæ•´æµ‹è¯•
    """
    
    def __init__(self, 
                 data_dir: str = "",
                 seg_dir: str = "",
                 datasets: List[str] = ["DUKE", "NACT", "ISPY1", "ISPY2"],
                 mode: str = "train",
                 train_ratio: float = 0.7,
                 val_ratio: float = 0.15,
                 input_channels: int = 1,
                 transform=None,
                 seed: int = 42,
                 multimodal: bool = False,
                 ser_dir: str = "",
                 pe_dir: str = "",
                 cross_dataset_test: bool = False):
        """
        Args:
            data_dir: åŸå§‹æ•°æ®è·¯å¾„
            seg_dir: åˆ†å‰²æ ‡ç­¾è·¯å¾„  
            datasets: è¦ä½¿ç”¨çš„æ•°æ®é›†åˆ—è¡¨
            mode: æ•°æ®é›†æ¨¡å¼
            train_ratio: è®­ç»ƒé›†æ¯”ä¾‹
            val_ratio: éªŒè¯é›†æ¯”ä¾‹
            input_channels: è¾“å…¥é€šé“æ•°
            transform: æ•°æ®å¢å¼º
            seed: éšæœºç§å­
            multimodal: æ˜¯å¦å¯ç”¨å¤šæ¨¡æ€è¾“å…¥
            ser_dir: SERå›¾åƒè·¯å¾„
            pe_dir: PEå›¾åƒè·¯å¾„
            cross_dataset_test: è·¨æ•°æ®é›†æµ‹è¯•æ¨¡å¼ï¼ˆæµ‹è¯•æ•´ä¸ªæ•°æ®é›†ï¼‰
        """
        super().__init__()
        
        self.data_dir = data_dir
        self.seg_dir = seg_dir
        self.datasets = [d.upper() for d in datasets]
        self.mode = mode
        self.input_channels = input_channels
        self.transform = transform
        self.multimodal = multimodal
        self.ser_dir = ser_dir
        self.pe_dir = pe_dir
        self.cross_dataset_test = cross_dataset_test
        
        # éªŒè¯é…ç½®
        if self.multimodal and self.input_channels != 3:
            print(f"è­¦å‘Š: å¤šæ¨¡æ€æ¨¡å¼ä¸‹è¾“å…¥é€šé“æ•°åº”ä¸º3ï¼Œä½†è®¾ç½®ä¸º{input_channels}ï¼Œè‡ªåŠ¨è°ƒæ•´ä¸º3")
            self.input_channels = 3
        
        # è·å–æ‰€æœ‰æ‚£è€…æ•°æ®
        self.patient_data = self._load_patient_data()
        
        # æ•°æ®é›†åˆ’åˆ†
        self.patient_ids = self._split_dataset(list(self.patient_data.keys()), 
                                             train_ratio, val_ratio, seed)
        
        print(f"MAMA-MIA Dataset Info:")
        print(f"  - Total patients: {len(self.patient_data)}")
        print(f"  - Selected datasets: {self.datasets}")
        print(f"  - Mode: {mode}, Patients: {len(self.patient_ids)}")
        print(f"  - Input channels: {self.input_channels}")
        print(f"  - Multi-modal: {self.multimodal}")
        if self.cross_dataset_test:
            print(f"  - Cross-dataset test: å®Œæ•´æ•°æ®é›†æµ‹è¯•æ¨¡å¼")
    
    def _load_patient_data(self) -> Dict[str, Dict]:
        """åŠ è½½æ‰€æœ‰æ‚£è€…çš„æ•°æ®è·¯å¾„ä¿¡æ¯"""
        patient_data = {}
        
        # éå†æ‰€æœ‰æ•°æ®é›†
        for dataset in self.datasets:
            dataset_pattern = os.path.join(self.data_dir, f"{dataset}_*")
            patient_folders = glob(dataset_pattern)
            
            for patient_folder in patient_folders:
                patient_id = os.path.basename(patient_folder)
                
                # æŸ¥æ‰¾T1æ—¶åˆ»å›¾åƒï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                t1_files = []
                for file in os.listdir(patient_folder):
                    if file.lower().endswith('_0001.nii.gz'):
                        t1_files.append(os.path.join(patient_folder, file))
                
                if len(t1_files) == 0:
                    print(f"Warning: No T1 image found for {patient_id}")
                    continue
                
                # å–ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„T1æ–‡ä»¶ï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªï¼‰
                t1_path = t1_files[0]
                
                # ã€æ–°å¢ã€‘å¤šæ¨¡æ€æ•°æ®åŠ è½½
                if self.multimodal:
                    # æŸ¥æ‰¾SERå›¾åƒ
                    ser_pattern = os.path.join(self.ser_dir, f"*{patient_id}*_FTV_SER_T1.nii.gz")
                    ser_files = glob(ser_pattern)
                    if len(ser_files) == 0:
                        print(f"Warning: No SER image found for {patient_id}")
                        continue
                    ser_path = ser_files[0]
                    
                    # æŸ¥æ‰¾PEå›¾åƒ  
                    pe_pattern = os.path.join(self.pe_dir, f"*{patient_id}*_FTV_PE_T1.nii.gz")
                    pe_files = glob(pe_pattern)
                    if len(pe_files) == 0:
                        print(f"Warning: No PE image found for {patient_id}")
                        continue
                    pe_path = pe_files[0]
                
                # æŸ¥æ‰¾å¯¹åº”çš„åˆ†å‰²æ ‡ç­¾
                seg_pattern = os.path.join(self.seg_dir, f"*{patient_id}*.nii.gz")
                seg_files = glob(seg_pattern)
                
                if len(seg_files) == 0:
                    print(f"Warning: No segmentation found for {patient_id}")
                    continue
                
                seg_path = seg_files[0]  # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„åˆ†å‰²æ–‡ä»¶
                
                if self.multimodal:
                    patient_data[patient_id] = {
                        't1_path': t1_path,
                        'ser_path': ser_path,
                        'pe_path': pe_path,
                        'seg_path': seg_path,
                        'dataset': dataset
                    }
                else:
                    patient_data[patient_id] = {
                        't1_path': t1_path,
                        'seg_path': seg_path,
                        'dataset': dataset
                    }
        
        return patient_data
    
    def _split_dataset(self, all_patients: List[str], train_ratio: float, 
                      val_ratio: float, seed: int) -> List[str]:
        """åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†"""
        
        if self.cross_dataset_test:
            print(f"è·¨æ•°æ®é›†æµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨æ•´ä¸ªæ•°æ®é›†çš„ {len(all_patients)} åæ‚£è€…")
            return all_patients
        
        np.random.seed(seed)
        np.random.shuffle(all_patients)
        
        n_total = len(all_patients)
        n_train = int(n_total * train_ratio)
        n_val = int(n_total * val_ratio)
        
        if self.mode == "train":
            return all_patients[:n_train]
        elif self.mode == "val":
            return all_patients[n_train:n_train + n_val]
        else:  # test
            test_patients = all_patients[n_train + n_val:]
            print(f"æ ‡å‡†æµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨ {len(test_patients)} åæ‚£è€…ï¼ˆæ€»æ‚£è€…æ•°: {n_total}ï¼‰")
            return test_patients
    
    def _load_nifti(self, file_path: str) -> np.ndarray:
        """åŠ è½½niftiæ–‡ä»¶å¹¶è¿”å›numpyæ•°ç»„"""
        img = nib.load(file_path)
        data = img.get_fdata()
        return data
    
    def _preprocess_data(self, image: np.ndarray, mask: np.ndarray, 
                        ser_image: np.ndarray = None, pe_image: np.ndarray = None) -> tuple:
        """æ•°æ®é¢„å¤„ç†"""
        # ç¡®ä¿æ˜¯3Dæ•°æ® [H, W, D]
        if image.ndim == 4:  # å¦‚æœæ˜¯4D [H, W, D, C]
            image = image[..., 0]  # å–ç¬¬ä¸€ä¸ªé€šé“
        
        if self.multimodal:
            if ser_image is None or pe_image is None:
                raise ValueError("å¤šæ¨¡æ€æ¨¡å¼ä¸‹éœ€è¦æä¾›SERå’ŒPEå›¾åƒ")
            
            # ç¡®ä¿æ‰€æœ‰æ¨¡æ€æ•°æ®å°ºå¯¸ä¸€è‡´
            if image.shape != ser_image.shape or image.shape != pe_image.shape:
                print(f"è­¦å‘Š: æ¨¡æ€æ•°æ®å°ºå¯¸ä¸ä¸€è‡´ - T1: {image.shape}, SER: {ser_image.shape}, PE: {pe_image.shape}")
                # ç»Ÿä¸€è°ƒæ•´åˆ°T1å›¾åƒçš„å°ºå¯¸
                target_shape = image.shape
                ser_image = self._resize_to_target(ser_image, target_shape)
                pe_image = self._resize_to_target(pe_image, target_shape)
        
        # ç»Ÿä¸€è°ƒæ•´å°ºå¯¸åˆ° [256, 256]
        target_size = (256, 256)
        if image.shape[0] != target_size[0] or image.shape[1] != target_size[1]:
            # è°ƒæ•´å›¾åƒå°ºå¯¸
            image = self._resize_3d(image, target_size)
            if self.multimodal:
                ser_image = self._resize_3d(ser_image, target_size)
                pe_image = self._resize_3d(pe_image, target_size)
            # è°ƒæ•´maskå°ºå¯¸ï¼ˆä½¿ç”¨æœ€è¿‘é‚»æ’å€¼ä¿æŒè¾¹ç¼˜æ¸…æ™°ï¼‰
            mask = self._resize_3d(mask, target_size, is_mask=True)
        
        # å½’ä¸€åŒ–
        image = (image - image.mean()) / (image.std() + 1e-8)
        if self.multimodal:
            ser_image = (ser_image - ser_image.mean()) / (ser_image.std() + 1e-8)
            pe_image = (pe_image - pe_image.mean()) / (pe_image.std() + 1e-8)
        
        # å¤„ç†maskï¼šäºŒå€¼åŒ–
        mask = (mask > 0).astype(np.float32)
        
        if self.multimodal:
            # å †å å¤šæ¨¡æ€æ•°æ® [3, H, W, D]
            multi_modal_image = np.stack([image, ser_image, pe_image], axis=0)
            image_tensor = multi_modal_image
        else:
            # å•æ¨¡æ€å¤„ç†
            if self.input_channels > 1:
                image_tensor = np.stack([image] * self.input_channels, axis=0)
            else:
                image_tensor = image[np.newaxis, ...]  # [1, H, W, D]
        
        mask_tensor = mask[np.newaxis, ...]  # [1, H, W, D]
        
        return image_tensor, mask_tensor
    
    def _resize_to_target(self, volume: np.ndarray, target_shape: tuple) -> np.ndarray:
        """å°†ä½“ç§¯è°ƒæ•´åˆ°ç›®æ ‡å½¢çŠ¶"""
        zoom_factors = (
            target_shape[0] / volume.shape[0],
            target_shape[1] / volume.shape[1], 
            target_shape[2] / volume.shape[2]
        )
        return zoom(volume, zoom_factors, order=1)
    
    def _resize_3d(self, volume: np.ndarray, target_size: tuple, is_mask: bool = False) -> np.ndarray:
        # è®¡ç®—ç¼©æ”¾å› å­
        h, w, d = volume.shape
        target_h, target_w = target_size
        
        zoom_factors = (target_h / h, target_w / w, 1)  # æ·±åº¦ç»´åº¦ä¿æŒä¸å˜
        
        if is_mask:
            # å¯¹äºmaskä½¿ç”¨æœ€è¿‘é‚»æ’å€¼
            resized = zoom(volume, zoom_factors, order=0)
        else:
            # å¯¹äºå›¾åƒä½¿ç”¨ä¸‰çº¿æ€§æ’å€¼
            resized = zoom(volume, zoom_factors, order=1)
        
        return resized

    def __len__(self):
        return len(self.patient_ids)
    
    def __getitem__(self, idx):
        patient_id = self.patient_ids[idx]
        patient_info = self.patient_data[patient_id]
        
        # åŠ è½½T1å›¾åƒå’Œåˆ†å‰²æ ‡ç­¾
        image = self._load_nifti(patient_info['t1_path'])
        mask = self._load_nifti(patient_info['seg_path'])
        
        ser_image = None
        pe_image = None
        if self.multimodal:
            ser_image = self._load_nifti(patient_info['ser_path'])
            pe_image = self._load_nifti(patient_info['pe_path'])
        
        # é¢„å¤„ç†
        image, mask = self._preprocess_data(image, mask, ser_image, pe_image)
        
        # è½¬æ¢ä¸ºtorch tensor
        image = torch.FloatTensor(image)  # [C, H, W, D]
        mask = torch.FloatTensor(mask)    # [1, H, W, D]
        
        meta = {
            'patient_id': patient_id, 
            'dataset': patient_info['dataset'],
            'reference_path': patient_info['t1_path']  # ç”¨äºä¿å­˜é¢„æµ‹ç»“æœæ—¶å‚è€ƒ
        }
        
        return image, mask, meta

class MAMAMIADataset2D(Dataset):
    """
    2Dåˆ‡ç‰‡ç‰ˆæœ¬çš„æ•°æ®é›†ï¼Œç”¨äºä¸åŸæœ‰U-KANæ¨¡å‹å…¼å®¹
    å°†3Dä½“ç§¯åˆ‡ç‰‡ä¸º2Då›¾åƒè¿›è¡Œè®­ç»ƒ
    ã€æ–°å¢ã€‘æ”¯æŒè·¨æ•°æ®é›†å®Œæ•´æµ‹è¯•
    ã€æ–°å¢ã€‘æ”¯æŒå¹³è¡¡é‡‡æ ·å’Œæ•°æ®å¢å¹¿
    """
    
    def __init__(self, 
                 data_dir: str = "",
                 seg_dir: str = "",
                 datasets: List[str] = ["DUKE", "NACT", "ISPY1", "ISPY2"],
                 mode: str = "train",
                 slice_axis: int = 2,  # åˆ‡ç‰‡è½´: 0=sagittal, 1=coronal, 2=axial
                 input_channels: int = 1,
                 transform=None,
                 seed: int = 42,
                 multimodal: bool = False,
                 ser_dir: str = "",
                 pe_dir: str = "",
                 cross_dataset_test: bool = False,
                 balanced_sampling: bool = False):
        
        self.slice_axis = slice_axis
        self.multimodal = multimodal
        self.cross_dataset_test = cross_dataset_test
        self.mode = mode
        self.transform = transform  
        self.balanced_sampling = balanced_sampling 
        
        self.original_dataset = MAMAMIADataset(
            data_dir=data_dir,
            seg_dir=seg_dir,
            datasets=datasets,
            mode=mode,
            input_channels=input_channels,
            transform=transform,
            seed=seed,
            multimodal=multimodal,  
            ser_dir=ser_dir,       
            pe_dir=pe_dir,         
            cross_dataset_test=cross_dataset_test 
        )
        
        # é¢„è®¡ç®—æ‰€æœ‰åˆ‡ç‰‡ç´¢å¼•
        self.slice_indices = []
        for patient_idx in range(len(self.original_dataset)):
            patient_id = self.original_dataset.patient_ids[patient_idx]
            patient_info = self.original_dataset.patient_data[patient_id]
            
            # è·å–ä½“ç§¯ç»´åº¦ä¿¡æ¯
            image = self.original_dataset._load_nifti(patient_info['t1_path'])
            if image.ndim == 4:
                image = image[..., 0]
            
            n_slices = image.shape[slice_axis]
            
            for slice_idx in range(n_slices):
                self.slice_indices.append((patient_idx, slice_idx))
        
        self.slice_weights = None
        if self.balanced_sampling and self.mode == "train":
            self._compute_slice_weights()
            print(f"å¹³è¡¡é‡‡æ ·æ¨¡å¼: å·²è®¡ç®—{len(self.slice_weights)}ä¸ªåˆ‡ç‰‡çš„æƒé‡")
        
        print(f"2Dåˆ‡ç‰‡æ•°æ®é›†: {len(self.slice_indices)} ä¸ªåˆ‡ç‰‡")
        if self.cross_dataset_test:
            print("ğŸ¯ è·¨æ•°æ®é›†æµ‹è¯•æ¨¡å¼: ä½¿ç”¨æ•´ä¸ªç›®æ ‡æ•°æ®é›†è¿›è¡Œæ³›åŒ–èƒ½åŠ›è¯„ä¼°")
    
    def _compute_slice_weights(self):
        """è®¡ç®—æ¯ä¸ªåˆ‡ç‰‡çš„æƒé‡ï¼ˆåŸºäºè‚¿ç˜¤é¢ç§¯ï¼‰"""
        self.slice_weights = []
        
        for (patient_idx, slice_idx) in self.slice_indices:
            patient_id = self.original_dataset.patient_ids[patient_idx]
            patient_info = self.original_dataset.patient_data[patient_id]
            
            # åŠ è½½maskä½“ç§¯
            mask_volume = self.original_dataset._load_nifti(patient_info['seg_path'])
            if mask_volume.ndim == 4:
                mask_volume = mask_volume[..., 0]
            
            # æå–è¯¥åˆ‡ç‰‡çš„mask
            if self.slice_axis == 0:  # sagittal
                mask_slice = mask_volume[slice_idx, :, :]
            elif self.slice_axis == 1:  # coronal
                mask_slice = mask_volume[:, slice_idx, :]
            else:  # axial (é»˜è®¤)
                mask_slice = mask_volume[:, :, slice_idx]
            
            # è®¡ç®—è‚¿ç˜¤åƒç´ æ¯”ä¾‹
            tumor_ratio = np.sum(mask_slice > 0) / mask_slice.size
            
            # æƒé‡è®¡ç®—ï¼šæœ‰è‚¿ç˜¤çš„åˆ‡ç‰‡æƒé‡æ›´é«˜
            # åŸºç¡€æƒé‡1.0 + è‚¿ç˜¤æ¯”ä¾‹ Ã— 10
            weight = 1.0 + tumor_ratio * 10.0
            self.slice_weights.append(weight)
    
    def get_weighted_sampler(self):
        """è¿”å›åŠ æƒé‡‡æ ·å™¨ï¼ˆç”¨äºDataLoaderï¼‰"""
        if self.slice_weights is None:
            raise ValueError("æœªå¯ç”¨å¹³è¡¡é‡‡æ ·æˆ–æœªè®¡ç®—åˆ‡ç‰‡æƒé‡")
        
        weights = torch.DoubleTensor(self.slice_weights)
        sampler = torch.utils.data.WeightedRandomSampler(
            weights, len(weights), replacement=True
        )
        return sampler
    
    def __len__(self):
        return len(self.slice_indices)
    
    def __getitem__(self, idx):
        patient_idx, slice_idx = self.slice_indices[idx]
        
        # è·å–å®Œæ•´çš„3Dæ•°æ®
        image_3d, mask_3d, meta = self.original_dataset[patient_idx]
        
        # æ²¿æŒ‡å®šè½´åˆ‡ç‰‡ [C, H, W, D] -> [C, H, W] æˆ– [C, H, D] æˆ– [C, W, D]
        if self.slice_axis == 0:  # sagittal
            image_2d = image_3d[:, slice_idx, :, :]  # [C, W, D]
            mask_2d = mask_3d[:, slice_idx, :, :]    # [1, W, D]
        elif self.slice_axis == 1:  # coronal  
            image_2d = image_3d[:, :, slice_idx, :]  # [C, H, D]
            mask_2d = mask_3d[:, :, slice_idx, :]    # [1, H, D]
        else:  # axial (é»˜è®¤)
            image_2d = image_3d[:, :, :, slice_idx]  # [C, H, W]
            mask_2d = mask_3d[:, :, :, slice_idx]    # [1, H, W]
        
        # ã€æ–°å¢ã€‘æ•°æ®å¢å¹¿ï¼ˆä»…åœ¨è®­ç»ƒæ¨¡å¼ä¸‹ä¸”å¯ç”¨äº†transformï¼‰
        if self.mode == "train" and self.transform is not None:
            image_2d, mask_2d = self.transform(image_2d, mask_2d)
        
        # æ›´æ–°metadata
        meta['slice_idx'] = slice_idx
        meta['slice_axis'] = self.slice_axis
        
        return image_2d, mask_2d, meta


def save_prediction_as_nifti(prediction: np.ndarray, reference_nifti_path: str, 
                           output_path: str, patient_id: str):
    """
    å°†é¢„æµ‹ç»“æœä¿å­˜ä¸ºniftiæ ¼å¼
    
    Args:
        prediction: é¢„æµ‹çš„åˆ†å‰²ç»“æœ [H, W, D]
        reference_nifti_path: å‚è€ƒniftiæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºè·å–å¤´ä¿¡æ¯ï¼‰
        output_path: è¾“å‡ºç›®å½•
        patient_id: æ‚£è€…ID
    """
    # åŠ è½½å‚è€ƒniftiè·å–å¤´ä¿¡æ¯
    ref_img = nib.load(reference_nifti_path)
    
    # åˆ›å»ºæ–°çš„niftiå›¾åƒ
    pred_img = nib.Nifti1Image(prediction, ref_img.affine, ref_img.header)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_path, exist_ok=True)
    
    # ä¿å­˜æ–‡ä»¶
    output_file = os.path.join(output_path, f"{patient_id}_pred.nii.gz")
    nib.save(pred_img, output_file)
    

    print(f"Prediction saved: {output_file}")

