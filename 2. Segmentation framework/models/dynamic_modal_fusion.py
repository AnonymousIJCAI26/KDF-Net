"""
è½»é‡çº§åŠ¨æ€æ¨¡æ€èåˆæ¨¡å— - æ”¹è¿›ç‰ˆ
æµ‹è¯•æ—¶ä½¿ç”¨è®­ç»ƒå†å²å‡å€¼æƒé‡
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from typing import Optional, Tuple, Dict, List
import os
from datetime import datetime

class DynamicModalFusion(nn.Module):
    """
    åŠ¨æ€æ¨¡æ€èåˆæ¨¡å— - æ”¹è¿›ç‰ˆ
    
    æ”¹è¿›ç‚¹ï¼š
    1. æµ‹è¯•æ—¶ä½¿ç”¨è®­ç»ƒå†å²å‡å€¼æƒé‡ï¼ˆæ›´ç¨³å¥ï¼‰
    2. æä¾›å¤šç§æƒé‡é€‰æ‹©ç­–ç•¥
    """
    
    def __init__(self, enabled: bool = True, verbose: bool = False, 
                 test_weight_method: str = 'historical_mean'):
        """
        Args:
            enabled: æ˜¯å¦å¯ç”¨åŠ¨æ€èåˆ
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯
            test_weight_method: æµ‹è¯•æ—¶æƒé‡é€‰æ‹©æ–¹æ³•
                - 'current': ä½¿ç”¨å½“å‰æƒé‡ï¼ˆåŸå§‹å®ç°ï¼‰
                - 'historical_mean': ä½¿ç”¨è®­ç»ƒå†å²å‡å€¼ï¼ˆæ¨èï¼‰
                - 'historical_median': ä½¿ç”¨è®­ç»ƒå†å²ä¸­ä½æ•°
                - 'last': ä½¿ç”¨æœ€åä¸€æ¬¡è®­ç»ƒæƒé‡
        """
        super().__init__()
        self.enabled = enabled
        self.verbose = verbose
        self.test_weight_method = test_weight_method
        
        if not enabled:
            if verbose:
                print("âš ï¸ Dynamic modal fusion is DISABLED. Using direct 3-channel input.")
            return
        
        print(f"ğŸ¯ DynamicModalFusion Initializing (test method: {test_weight_method})...")
        
        # ==================== æè½»é‡èåˆç»„ä»¶ ====================
        self.conv_t1 = nn.Conv2d(1, 1, 1, bias=False)  # T1æ˜ å°„
        self.conv_ser = nn.Conv2d(1, 1, 1, bias=False)  # SERæ˜ å°„
        self.conv_pe = nn.Conv2d(1, 1, 1, bias=False)   # PEæ˜ å°„
        
        # å¯å­¦ä¹ çš„æ¨¡æ€æƒé‡ [3]
        self.modal_weights = nn.Parameter(torch.ones(3) / 3.0)
        
        # ==================== èåˆåè°ƒæ•´ ====================
        self.fusion_adjust = nn.Conv2d(3, 3, 1, bias=False)
        
        # ==================== ã€æ–°å¢ã€‘è®­ç»ƒå†å²å­˜å‚¨ ====================
        # å­˜å‚¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„å½’ä¸€åŒ–æƒé‡ï¼ˆç”¨äºæµ‹è¯•æ—¶è®¡ç®—å‡å€¼ï¼‰
        self._train_normalized_history = []  # å­˜å‚¨è®­ç»ƒæ—¶çš„å½’ä¸€åŒ–æƒé‡
        self._train_raw_history = []  # å­˜å‚¨è®­ç»ƒæ—¶çš„åŸå§‹æƒé‡
        self._train_sample_count = 0  # è®­ç»ƒæ ·æœ¬è®¡æ•°
        
        # å¯è§£é‡Šæ€§å­˜å‚¨
        self.modal_weights_history = []  # å­˜å‚¨æƒé‡å†å²ï¼ˆç”¨äºåˆ†æï¼‰
        self.modal_statistics_history = []  # å­˜å‚¨ç»Ÿè®¡ç‰¹å¾å†å²
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
        
        # è®¡ç®—å¹¶æ‰“å°å¢åŠ çš„å‚æ•°é‡
        self._print_parameter_info()
        
        if verbose:
            print("âœ… DynamicModalFusion initialized successfully")
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        if not self.enabled:
            return
        
        # ç®€å•çš„æƒé‡åˆå§‹åŒ–
        def init_simple(conv_layer):
            nn.init.normal_(conv_layer.weight, mean=1.0, std=0.01)
        
        init_simple(self.conv_t1)
        init_simple(self.conv_ser)
        init_simple(self.conv_pe)
        
        # æ¨¡æ€æƒé‡åˆå§‹åŒ–ä¸ºå¹³å‡åˆ†é…
        with torch.no_grad():
            self.modal_weights.copy_(torch.ones(3) / 3.0)
        
        # èåˆè°ƒæ•´åˆå§‹åŒ–ä¸ºæ¥è¿‘å•ä½çŸ©é˜µ
        nn.init.normal_(self.fusion_adjust.weight, mean=1.0, std=0.01)
    
    def _print_parameter_info(self):
        """æ‰“å°å‚æ•°é‡ä¿¡æ¯"""
        if not self.enabled:
            return
        
        total_params = sum(p.numel() for p in self.parameters())
        print(f"ğŸ¯ DynamicModalFusion Parameters: {total_params:,} ({total_params/1e6:.6f}M)")
    
    def compute_modal_statistics(self, t1: torch.Tensor, ser: torch.Tensor, pe: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—æ¨¡æ€ç»Ÿè®¡ç‰¹å¾"""
        B = t1.shape[0]
        stats_list = []
        
        for modal in [t1, ser, pe]:
            modal_flat = modal.view(B, -1)
            mean_val = modal_flat.mean(dim=1, keepdim=True)
            std_val = modal_flat.std(dim=1, keepdim=True)
            modal_stats = torch.cat([mean_val, std_val], dim=1)
            stats_list.append(modal_stats)
        
        return torch.cat(stats_list, dim=1)  # [B, 6]
    
    def _get_normalized_weights(self) -> torch.Tensor:
        """è·å–å½’ä¸€åŒ–æƒé‡ï¼ˆsoftmaxç¡®ä¿å’Œä¸º1ï¼‰"""
        return torch.softmax(self.modal_weights, dim=0)  # [3]
    
    def _get_test_weights(self) -> torch.Tensor:
        """
        è·å–æµ‹è¯•æ—¶ä½¿ç”¨çš„æƒé‡
        
        æ ¹æ®test_weight_methodé€‰æ‹©ï¼š
        - 'current': å½“å‰æƒé‡
        - 'historical_mean': è®­ç»ƒå†å²å‡å€¼ï¼ˆæ¨èï¼‰
        - 'historical_median': è®­ç»ƒå†å²ä¸­ä½æ•°
        - 'last': æœ€åä¸€æ¬¡è®­ç»ƒæƒé‡
        """
        if self.test_weight_method == 'current':
            # åŸå§‹å®ç°ï¼šä½¿ç”¨å½“å‰æƒé‡
            return self._get_normalized_weights()
        
        elif self.test_weight_method in ['historical_mean', 'historical_median', 'last']:
            # éœ€è¦è®­ç»ƒå†å²æ•°æ®
            if not self._train_normalized_history:
                if self.verbose:
                    print("âš ï¸ No training history, using current weights")
                return self._get_normalized_weights()
            
            # å°†å†å²æ•°æ®è½¬æ¢ä¸ºtensor
            history_tensor = torch.stack(self._train_normalized_history)  # [N, 3]
            
            if self.test_weight_method == 'historical_mean':
                return history_tensor.mean(dim=0)
            elif self.test_weight_method == 'historical_median':
                return history_tensor.median(dim=0).values
            elif self.test_weight_method == 'last':
                return history_tensor[-1]
        
        else:
            # æœªçŸ¥æ–¹æ³•ï¼Œä½¿ç”¨å½“å‰æƒé‡
            print(f"âš ï¸ Unknown test_weight_method: {self.test_weight_method}, using 'current'")
            return self._get_normalized_weights()
    
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: [B, 3, H, W] ä¸‰é€šé“è¾“å…¥
            
        Returns:
            è®­ç»ƒæ¨¡å¼: (fused_features, weight_matrix)
            æµ‹è¯•æ¨¡å¼: fused_features
        """
        if not self.enabled:
            dummy_weights = torch.ones(x.shape[0], 3, device=x.device) / 3.0
            return (x, dummy_weights) if self.training else x
        
        B, C, H, W = x.shape
        if C != 3:
            raise ValueError(f"Expected 3-channel input, got {C} channels")
        
        # åˆ†ç¦»æ¨¡æ€
        t1 = x[:, 0:1, :, :]
        ser = x[:, 1:2, :, :]
        pe = x[:, 2:3, :, :]
        
        # ç‹¬ç«‹ç‰¹å¾æå–
        f_t1 = self.conv_t1(t1)
        f_ser = self.conv_ser(ser)
        f_pe = self.conv_pe(pe)
        
        # ã€å…³é”®æ”¹è¿›ã€‘æ ¹æ®è®­ç»ƒ/æµ‹è¯•æ¨¡å¼é€‰æ‹©æƒé‡
        if self.training:
            # è®­ç»ƒæ¨¡å¼ï¼šä½¿ç”¨å½“å‰æƒé‡ï¼Œå¹¶è®°å½•å†å²
            current_normalized = self._get_normalized_weights()
            weights_to_use = current_normalized
            
            # è®°å½•è®­ç»ƒå†å²ï¼ˆæ¯100ä¸ªæ ·æœ¬è®°å½•ä¸€æ¬¡ï¼Œé¿å…å†…å­˜è¿‡å¤§ï¼‰
            self._train_sample_count += B
            if self._train_sample_count >= 100:
                self._train_normalized_history.append(current_normalized.detach().clone())
                self._train_raw_history.append(self.modal_weights.detach().clone())
                self._train_sample_count = 0
                
                # é™åˆ¶å†å²é•¿åº¦ï¼ˆæœ€å¤šä¿å­˜1000ä¸ªè®°å½•ï¼‰
                if len(self._train_normalized_history) > 1000:
                    self._train_normalized_history.pop(0)
                    self._train_raw_history.pop(0)
        else:
            # æµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨æŒ‡å®šçš„å†å²ç»Ÿè®¡æ–¹æ³•
            weights_to_use = self._get_test_weights()
        
        W1, W2, W3 = weights_to_use[0], weights_to_use[1], weights_to_use[2]
        
        # åŠ¨æ€åŠ æƒèåˆ
        fused_weighted = W1 * f_t1 + W2 * f_ser + W3 * f_pe
        
        # è°ƒæ•´èåˆç‰¹å¾
        fused_repeated = fused_weighted.repeat(1, 3, 1, 1)
        fused_adjusted = self.fusion_adjust(fused_repeated)
        
        # ä¿å­˜å¯è§£é‡Šæ€§æ•°æ®ï¼ˆè®­ç»ƒå’Œæµ‹è¯•éƒ½ä¿å­˜ï¼‰
        with torch.no_grad():
            # ä¿å­˜æƒé‡ç”¨äºåˆ†æ
            weights_cpu = weights_to_use.detach().cpu().numpy()
            expanded_weights = np.tile(weights_cpu, (B, 1))
            self.modal_weights_history.append(expanded_weights)
            
            # ä¿å­˜ç»Ÿè®¡ç‰¹å¾
            stats = self.compute_modal_statistics(t1, ser, pe)
            self.modal_statistics_history.append(stats.detach().cpu().numpy())
        
        if self.verbose and not self.training:
            print(f"\nğŸ” Dynamic Fusion (test mode):")
            print(f"   Method: {self.test_weight_method}")
            print(f"   Weights: T1={W1:.3f}, SER={W2:.3f}, PE={W3:.3f}")
        
        # åˆ›å»ºæƒé‡çŸ©é˜µç”¨äºè¿”å›
        weight_matrix = weights_to_use.unsqueeze(0).repeat(B, 1)
        
        if self.training:
            return fused_adjusted, weight_matrix
        else:
            return fused_adjusted
    
    def get_weight_history(self) -> np.ndarray:
        """è·å–æƒé‡å†å²æ•°æ®"""
        if not self.modal_weights_history:
            return np.array([])
        try:
            return np.concatenate(self.modal_weights_history, axis=0)
        except Exception as e:
            print(f"âš ï¸ Failed to get weight history: {e}")
            return np.array([])
    
    def get_fusion_analysis(self) -> Dict:
        """è·å–èåˆåˆ†æç»“æœ"""
        if not self.enabled:
            return {"status": "Fusion not enabled"}
        
        try:
            analysis = {
                "status": "success",
                "test_weight_method": self.test_weight_method,
                "train_history_size": len(self._train_normalized_history),
                "num_samples": len(self.modal_weights_history) * (100 if self._train_sample_count > 0 else 0),
                "current_weights": {
                    "T1": float(self.modal_weights[0].item()),
                    "SER": float(self.modal_weights[1].item()),
                    "PE": float(self.modal_weights[2].item()),
                    "normalized_T1": float(self._get_normalized_weights()[0].item()),
                    "normalized_SER": float(self._get_normalized_weights()[1].item()),
                    "normalized_PE": float(self._get_normalized_weights()[2].item()),
                }
            }
            
            # å¦‚æœæœ‰è®­ç»ƒå†å²ï¼Œè®¡ç®—å†å²ç»Ÿè®¡
            if self._train_normalized_history:
                history_tensor = torch.stack(self._train_normalized_history)
                analysis["historical_statistics"] = {
                    "mean_T1": float(history_tensor[:, 0].mean().item()),
                    "mean_SER": float(history_tensor[:, 1].mean().item()),
                    "mean_PE": float(history_tensor[:, 2].mean().item()),
                    "std_T1": float(history_tensor[:, 0].std().item()),
                    "std_SER": float(history_tensor[:, 1].std().item()),
                    "std_PE": float(history_tensor[:, 2].std().item()),
                    "median_T1": float(history_tensor[:, 0].median().item()),
                    "median_SER": float(history_tensor[:, 1].median().item()),
                    "median_PE": float(history_tensor[:, 2].median().item()),
                }
                
                # å½“å‰æµ‹è¯•æƒé‡
                test_weights = self._get_test_weights()
                analysis["test_weights"] = {
                    "T1": float(test_weights[0].item()),
                    "SER": float(test_weights[1].item()),
                    "PE": float(test_weights[2].item()),
                    "method": self.test_weight_method
                }
            
            # å¦‚æœæœ‰å¯è§£é‡Šæ€§æ•°æ®
            if self.modal_weights_history:
                all_weights = self.get_weight_history()
                if len(all_weights) > 0:
                    analysis["modal_weights"] = {
                        "num_samples": len(all_weights),
                        "T1_mean": float(all_weights[:, 0].mean()),
                        "T1_std": float(all_weights[:, 0].std()),
                        "SER_mean": float(all_weights[:, 1].mean()),
                        "SER_std": float(all_weights[:, 1].std()),
                        "PE_mean": float(all_weights[:, 2].mean()),
                        "PE_std": float(all_weights[:, 2].std()),
                    }
            
            return analysis
            
        except Exception as e:
            return {"status": f"error: {str(e)}"}
    
    def reset_history(self):
        """é‡ç½®å†å²è®°å½•"""
        self._train_normalized_history = []
        self._train_raw_history = []
        self._train_sample_count = 0
        self.modal_weights_history = []
        self.modal_statistics_history = []
    
    def get_current_weights(self) -> torch.Tensor:
        """è·å–å½“å‰å½’ä¸€åŒ–çš„æ¨¡æ€æƒé‡"""
        return self._get_normalized_weights()
    
    def get_test_weights_info(self) -> Dict:
        """è·å–æµ‹è¯•æƒé‡ä¿¡æ¯"""
        test_weights = self._get_test_weights()
        return {
            "method": self.test_weight_method,
            "weights": test_weights.detach().cpu().numpy(),
            "has_history": len(self._train_normalized_history) > 0
        }


class FusionVisualizer:
    """èåˆå¯è§†åŒ–å·¥å…·"""
    
    @staticmethod
    def plot_modal_weights(weights_data: np.ndarray, save_path: Optional[str] = None):
        """
        ç»˜åˆ¶æ¨¡æ€æƒé‡åˆ†å¸ƒ
        
        Args:
            weights_data: [N, 3] æƒé‡æ•°æ®
            save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        if len(weights_data) == 0:
            print("âš ï¸ No weight data to visualize")
            return
        
        fig, axes = plt.subplots(1, 3, figsize=(15, 4))
        modal_names = ['T1', 'SER', 'PE']
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
        
        for idx, (ax, name, color) in enumerate(zip(axes, modal_names, colors)):
            ax.hist(weights_data[:, idx], bins=20, alpha=0.7, color=color, edgecolor='black')
            ax.set_title(f'{name} Weight Distribution', fontsize=12, fontweight='bold')
            ax.set_xlabel('Weight Value', fontsize=10)
            ax.set_ylabel('Frequency', fontsize=10)
            ax.grid(True, alpha=0.3)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            mean_val = weights_data[:, idx].mean()
            std_val = weights_data[:, idx].std()
            ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, 
                      label=f'Mean: {mean_val:.3f}\nStd: {std_val:.3f}')
            ax.legend(loc='upper right')
        
        plt.suptitle('Dynamic Modal Weight Distributions', fontsize=14, fontweight='bold')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š Weight distribution plot saved to: {save_path}")
        
        plt.show()
        plt.close()
    
    @staticmethod
    def plot_weight_evolution(weight_history: List[np.ndarray], save_path: Optional[str] = None):
        """
        ç»˜åˆ¶æƒé‡éšè®­ç»ƒçš„å˜åŒ–
        
        Args:
            weight_history: æƒé‡å†å²åˆ—è¡¨
            save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        if not weight_history:
            print("âš ï¸ No weight history to visualize")
            return
        
        # å°†å†å²æ•°æ®è½¬æ¢ä¸ºæ•°ç»„
        all_weights = np.concatenate(weight_history, axis=0)
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # ç»˜åˆ¶ä¸‰æ¡æ›²çº¿
        modal_names = ['T1', 'SER', 'PE']
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
        
        for i in range(3):
            ax.plot(all_weights[:, i], label=modal_names[i], color=colors[i], linewidth=2, alpha=0.8)
        
        ax.set_xlabel('Sample Index', fontsize=12)
        ax.set_ylabel('Weight Value', fontsize=12)
        ax.set_title('Modal Weight Evolution During Training', fontsize=14, fontweight='bold')
        ax.legend(loc='upper right')
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ ç§»åŠ¨å¹³å‡çº¿
        window_size = min(50, len(all_weights) // 10)
        if window_size > 1:
            for i in range(3):
                moving_avg = np.convolve(all_weights[:, i], np.ones(window_size)/window_size, mode='valid')
                ax.plot(range(window_size-1, len(all_weights)), moving_avg, 
                       color=colors[i], linestyle='--', alpha=0.5, linewidth=1)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ Weight evolution plot saved to: {save_path}")
        
        plt.show()
        plt.close()
    
    @staticmethod
    def generate_fusion_report(fusion_module: DynamicModalFusion, 
                               output_dir: str = "./fusion_analysis"):
        """
        ç”Ÿæˆå®Œæ•´çš„èåˆåˆ†ææŠ¥å‘Š
        
        Args:
            fusion_module: èåˆæ¨¡å—å®ä¾‹
            output_dir: è¾“å‡ºç›®å½•
        """
        if not fusion_module.enabled:
            print("âš ï¸ Fusion module is not enabled. No report generated.")
            return
        
        os.makedirs(output_dir, exist_ok=True)
        
        # è·å–åˆ†ææ•°æ®
        analysis = fusion_module.get_fusion_analysis()
        
        if analysis["status"] != "success":
            print(f"âŒ Failed to get fusion analysis: {analysis}")
            return
        
        # 1. ä¿å­˜åˆ†æç»“æœä¸ºJSON
        import json
        report_path = os.path.join(output_dir, "fusion_report.json")
        with open(report_path, 'w') as f:
            json.dump(analysis, f, indent=2, default=str)
        print(f"ğŸ“„ Fusion report saved to: {report_path}")
        
        # 2. ç»˜åˆ¶æƒé‡åˆ†å¸ƒ
        weight_data = fusion_module.get_weight_history()
        if len(weight_data) > 0:
            weight_plot_path = os.path.join(output_dir, "weight_distribution.png")
            FusionVisualizer.plot_modal_weights(weight_data, weight_plot_path)
        
        # 3. ç»˜åˆ¶æƒé‡æ¼”åŒ–
        if fusion_module.modal_weights_history:
            evolution_path = os.path.join(output_dir, "weight_evolution.png")
            FusionVisualizer.plot_weight_evolution(fusion_module.modal_weights_history, evolution_path)
        
        # 4. ç”Ÿæˆæ–‡æœ¬æ€»ç»“
        summary_path = os.path.join(output_dir, "summary.txt")
        with open(summary_path, 'w') as f:
            f.write("=" * 50 + "\n")
            f.write("DYNAMIC MODAL FUSION ANALYSIS REPORT\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Test Weight Method: {analysis.get('test_weight_method', 'N/A')}\n")
            f.write(f"Train History Size: {analysis.get('train_history_size', 0)}\n\n")
            
            # å½“å‰æƒé‡
            current_weights = analysis.get('current_weights', {})
            if current_weights:
                f.write("Current Weights:\n")
                f.write("-" * 30 + "\n")
                f.write(f"Raw weights:\n")
                f.write(f"  T1: {current_weights.get('T1', 0):.4f}\n")
                f.write(f"  SER: {current_weights.get('SER', 0):.4f}\n")
                f.write(f"  PE: {current_weights.get('PE', 0):.4f}\n\n")
                
                f.write(f"Normalized weights:\n")
                f.write(f"  T1: {current_weights.get('normalized_T1', 0):.4f}\n")
                f.write(f"  SER: {current_weights.get('normalized_SER', 0):.4f}\n")
                f.write(f"  PE: {current_weights.get('normalized_PE', 0):.4f}\n\n")
            
            # æµ‹è¯•æƒé‡
            test_weights = analysis.get('test_weights', {})
            if test_weights:
                f.write("Test Weights (for inference):\n")
                f.write("-" * 30 + "\n")
                f.write(f"Method: {test_weights.get('method', 'N/A')}\n")
                f.write(f"T1: {test_weights.get('T1', 0):.4f}\n")
                f.write(f"SER: {test_weights.get('SER', 0):.4f}\n")
                f.write(f"PE: {test_weights.get('PE', 0):.4f}\n\n")
            
            # æ¨¡æ€æƒé‡ç»Ÿè®¡
            modal_weights = analysis.get('modal_weights', {})
            if modal_weights:
                f.write("Modal Weight Statistics:\n")
                f.write("-" * 30 + "\n")
                f.write(f"Number of samples: {modal_weights.get('num_samples', 0)}\n")
                f.write(f"T1: Mean = {modal_weights.get('T1_mean', 0):.4f}, Std = {modal_weights.get('T1_std', 0):.4f}\n")
                f.write(f"SER: Mean = {modal_weights.get('SER_mean', 0):.4f}, Std = {modal_weights.get('SER_std', 0):.4f}\n")
                f.write(f"PE: Mean = {modal_weights.get('PE_mean', 0):.4f}, Std = {modal_weights.get('PE_std', 0):.4f}\n\n")
            
            # å†å²ç»Ÿè®¡
            historical_stats = analysis.get('historical_statistics', {})
            if historical_stats:
                f.write("Historical Statistics:\n")
                f.write("-" * 30 + "\n")
                f.write(f"Mean: T1={historical_stats.get('mean_T1', 0):.4f}, "
                       f"SER={historical_stats.get('mean_SER', 0):.4f}, "
                       f"PE={historical_stats.get('mean_PE', 0):.4f}\n")
                f.write(f"Std: T1={historical_stats.get('std_T1', 0):.4f}, "
                       f"SER={historical_stats.get('std_SER', 0):.4f}, "
                       f"PE={historical_stats.get('std_PE', 0):.4f}\n\n")
            
            # åˆ¤æ–­ä¸»å¯¼æ¨¡æ€
            if current_weights:
                normalized_weights = [
                    current_weights.get('normalized_T1', 0),
                    current_weights.get('normalized_SER', 0),
                    current_weights.get('normalized_PE', 0)
                ]
                if sum(normalized_weights) > 0:
                    dominant_idx = np.argmax(normalized_weights)
                    modal_names = ['T1', 'SER', 'PE']
                    
                    f.write(f"Dominant Modal: {modal_names[dominant_idx]} ")
                    f.write(f"({normalized_weights[dominant_idx]:.3f})\n\n")
                    
                    # åŒ»å­¦è§£é‡Š
                    f.write("Medical Interpretation:\n")
                    f.write("-" * 30 + "\n")
                    if normalized_weights[0] > 0.4:
                        f.write("â€¢ T1 dominant: Strong anatomical structure information\n")
                    if normalized_weights[1] > 0.4:
                        f.write("â€¢ SER dominant: Strong hemodynamic information\n")
                    if normalized_weights[2] > 0.4:
                        f.write("â€¢ PE dominant: Strong perfusion heterogeneity information\n")
                    if sum(normalized_weights) > 0.9:
                        f.write("â€¢ Good weight normalization (sum close to 1.0)\n")
        
        print(f"ğŸ“‹ Fusion analysis complete. Results saved to: {output_dir}")


# ==================== æµ‹è¯•å‡½æ•° ====================
def test_dynamic_fusion():
    """æµ‹è¯•åŠ¨æ€èåˆæ¨¡å—"""
    print("ğŸ§ª Testing DynamicModalFusion...")
    
    # åˆ›å»ºæ¨¡å—
    fusion = DynamicModalFusion(enabled=True, verbose=True)
    
    # æµ‹è¯•è¾“å…¥ [batch_size=4, channels=3, height=256, width=256]
    test_input = torch.randn(4, 3, 256, 256)
    print(f"\nTest input shape: {test_input.shape}")
    
    # æµ‹è¯•è®­ç»ƒæ¨¡å¼
    print("\n--- Testing Training Mode ---")
    fusion.train()
    output, weights = fusion(test_input)
    print(f"Output shape: {output.shape}")
    print(f"Weights shape: {weights.shape}")
    print(f"Weights (first sample): {weights[0].detach().numpy()}")
    
    # æµ‹è¯•æ¨ç†æ¨¡å¼
    print("\n--- Testing Inference Mode ---")
    fusion.eval()
    with torch.no_grad():
        output_inference = fusion(test_input)
    print(f"Inference output shape: {output_inference.shape}")
    
    # æµ‹è¯•è·å–å½“å‰æƒé‡
    current_weights = fusion.get_current_weights()
    print(f"\nCurrent normalized weights: {current_weights.detach().numpy()}")
    
    # æµ‹è¯•åˆ†æåŠŸèƒ½
    analysis = fusion.get_fusion_analysis()
    print(f"\nFusion analysis status: {analysis['status']}")
    
    # æµ‹è¯•æƒé‡å†å²
    weight_history = fusion.get_weight_history()
    print(f"\nWeight history shape: {weight_history.shape}")
    
    print("\nâœ… DynamicModalFusion test completed successfully!")
    return fusion


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_dynamic_fusion()